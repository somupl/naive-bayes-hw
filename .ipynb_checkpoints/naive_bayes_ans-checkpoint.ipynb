{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "import nltk\n",
    "import unicodedata\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our belief before starting the experiment is equally distributed {1: 0.3333333333333333, 2: 0.3333333333333333, 3: 0.3333333333333333}\n",
      "--------------------------------------------------\n",
      "selected coin is 1, we dont know this, we need to find through experiment and verify\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.2333333333333333, 0.18333333333333335, 0.08333333333333333]\n",
      " \n",
      "updating our belief based on evidence {1: 0.4666666666666667, 2: 0.36666666666666675, 3: 0.16666666666666669}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: H\n",
      "evidence of getting H based on our belief is: [0.13999999999999999, 0.16500000000000004, 0.125]\n",
      " \n",
      "updating our belief based on evidence {1: 0.3255813953488371, 2: 0.38372093023255816, 3: 0.2906976744186046}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.22790697674418597, 0.211046511627907, 0.07267441860465115]\n",
      " \n",
      "updating our belief based on evidence {1: 0.4454545454545454, 2: 0.4125000000000001, 3: 0.14204545454545456}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.31181818181818177, 0.22687500000000008, 0.03551136363636364]\n",
      " \n",
      "updating our belief based on evidence {1: 0.5430437363942212, 2: 0.39511181476350693, 3: 0.06184444884227192}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.38013061547595484, 0.21731149811992884, 0.01546111221056798]\n",
      " \n",
      "updating our belief based on evidence {1: 0.6202131094607684, 2: 0.3545608653535681, 3: 0.025226025185663546}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.4341491766225378, 0.1950084759444625, 0.0063065062964158865]\n",
      " \n",
      "updating our belief based on evidence {1: 0.683200099591851, 2: 0.3068756486490951, 3: 0.009924251759053775}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.47824006971429567, 0.16878160675700232, 0.0024810629397634437]\n",
      " \n",
      "updating our belief based on evidence {1: 0.7363172480965073, 2: 0.25986280967813247, 3: 0.003819942225360212}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.5154220736675551, 0.14292454532297286, 0.000954985556340053]\n",
      " \n",
      "updating our belief based on evidence {1: 0.7817697850467086, 2: 0.21678173439484283, 3: 0.0014484805584485205}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.547238849532696, 0.11922995391716357, 0.00036212013961213013]\n",
      " \n",
      "updating our belief based on evidence {1: 0.8206560766362997, 2: 0.17880087695298064, 3: 0.0005430464107196475}\n",
      "--------------------------------------------------\n",
      "flip a coin\n",
      "flip: T\n",
      "evidence of getting T based on our belief is: [0.5744592536454097, 0.09834048232413936, 0.00013576160267991187]\n",
      " \n",
      "updating our belief based on evidence {1: 0.8536616892969754, 2: 0.14613656536016523, 3: 0.00020174534285931318}\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "experimental ans is 1 and actual ans is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: fg: no job control\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "%cd ~/galvanized/week10/naive-bayes-hw\n",
    "python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Independent assumption makes naive bayes classifier so naive\n",
    "\n",
    "- **Types Naive Bayes Classifiers**\n",
    "\n",
    "    - Bernoulli: Used when outcome is 0 / 1. underlying distribution is Bernoulli. \n",
    "\n",
    "    - Gaussian: Used when outcome is real number with normal distribution assumption. \n",
    "\n",
    "    - Multinomial: Used when you repeat an experiment N number of times and outcome of the experiment is more than 2 possible values. [counting more than 2 possible outcomes]\n",
    "\n",
    "- we can still use naive bayes classifier if the features are independent. We can assume that they are independent even though they are not, it still works well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = pd.read_csv('grad.csv')\n",
    "grad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score:  0.725\n",
      "Random Forest Score:  0.7\n",
      "Guassian NB Score:  0.7083333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ej7hz6f\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "y = grad.admit\n",
    "X = grad[['gre', 'gpa', 'rank']]\n",
    "\n",
    "# test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 42)\n",
    "\n",
    "# standard scalar\n",
    "scalar = MinMaxScaler().fit(X_train)\n",
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "model1 = LogisticRegression(solver = 'lbfgs').fit(X_train, y_train)\n",
    "print(\"Logistic Regression Score: \", accuracy_score(y_test, model1.predict(X_test)))\n",
    "\n",
    "# Random Forest\n",
    "model2 = RandomForestClassifier(n_estimators=4).fit(X_train, y_train)\n",
    "print(\"Random Forest Score: \", accuracy_score(y_test, model2.predict(X_test)))\n",
    "\n",
    "# Guassian Naive Bayes\n",
    "model3 = GaussianNB().fit(X_train, y_train)\n",
    "print('Guassian NB Score: ', accuracy_score(y_test, model3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression performs well compared to other 2 models, depending on the run Random Forest can perform well but most of the time random forest performance is bad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/galvanized/week9/twitter_sentiment/twitter-airline-sentiment/Tweets.csv')\n",
    "text = data.pop('text')\n",
    "label = data.pop('airline_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 14640)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text), len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(n):\n",
    "    n = n.lower()\n",
    "    return unicodedata.normalize('NFKD', n).encode('ASCII', 'ignore').decode('utf-8')\n",
    "\n",
    "# normalize string after converting it into lower case using above function. \n",
    "normalize = list(map(myfunc, text))\n",
    "\n",
    "# Remove stop words\n",
    "sw = stopwords.words('english')\n",
    "pt = string.punctuation\n",
    "filtered = list(filter(lambda token: token not in sw and token not in pt, normalize))\n",
    "\n",
    "# Stemming\n",
    "stemmer_snowball = SnowballStemmer('english')\n",
    "tokens_stemsnowball = list(map(stemmer_snowball.stem, filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(tokens_stemsnowball)\n",
    "#print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB Score:  0.7745901639344263\n"
     ]
    }
   ],
   "source": [
    "model3 = MultinomialNB().fit(X_train, y_train)\n",
    "print('Multinomial NB Score: ', accuracy_score(y_test, model3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn clustering model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7169854280510018"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7, algorithm='brute', metric = 'cosine')\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes model performed better than Kmeans Model**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
